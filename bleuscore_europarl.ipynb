{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0f107b-6e3e-40c1-a20e-da6ba3c0c1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5263903c3e3f42ce8355d868b81af4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/842 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5710eb431ad49398a13c07db40af8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/789k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb414c729db49cf9f8203fd801b223b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/814k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0104817dbaf4d69b7a18226e6cbd356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085dba9fe7364807839aad388bfcbcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100c4213fd174b489b87cc45f8a4796b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a8d145dbe44be397d6f7ea31ed2cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/341M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3254cde1cdc845a2b25861a73fed9f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore: Il testo non è di tipo str, ma <class 'float'>\n",
      "Errore: Il testo non è di tipo str, ma <class 'float'>\n",
      "Errore: Il testo non è di tipo str, ma <class 'float'>\n",
      "Errore: Il testo non è di tipo str, ma <class 'float'>\n",
      "File CSV con traduzioni creato: europarl_translations.csv\n"
     ]
    }
   ],
   "source": [
    "# Parte 1: Traduzione e salvataggio delle traduzioni\n",
    "import pandas as pd\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "\n",
    "# Carica i modelli di traduzione e i tokenizer\n",
    "model_names = [\n",
    "    \"Helsinki-NLP/opus-mt-en-it\",\n",
    "    \"Gopal1853/Gopal-finetuned-custom-en-to-it\",\n",
    "    \"Anhptp/opus-mt-en-it-BDS-G1\",\n",
    "    \"callmyname/marian-finetuned-kde4-en-to-it\"\n",
    "]\n",
    "\n",
    "models = {}\n",
    "tokenizers = {}\n",
    "for model_name in model_names:\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    models[model_name] = model\n",
    "    tokenizers[model_name] = tokenizer\n",
    "\n",
    "# Carica il corpus\n",
    "file_input_csv = 'europarl_unito_500righe.csv'\n",
    "df = pd.read_csv(file_input_csv, delimiter=';')\n",
    "\n",
    "translations_dict = {model_name: [] for model_name in model_names}\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = models[model_name]\n",
    "    tokenizer = tokenizers[model_name]\n",
    "\n",
    "    english_texts = df['Inglese'].tolist()\n",
    "\n",
    "    translations = []\n",
    "    for text in english_texts:\n",
    "        if isinstance(text, str):\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "            outputs = model.generate(**inputs)\n",
    "            translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            translations.append(translation)\n",
    "        else:\n",
    "            print(f\"Errore: Il testo non è di tipo str, ma {type(text)}\")\n",
    "            translations.append(\"\")\n",
    "\n",
    "    translations_dict[model_name] = translations\n",
    "\n",
    "# Salva le traduzioni in un file CSV\n",
    "file_translations_csv = 'europarl_translations.csv'\n",
    "df_output = pd.DataFrame()\n",
    "df_output['Italiano'] = df['Italiano']\n",
    "df_output['Inglese'] = df['Inglese']\n",
    "\n",
    "for model_name, translations in translations_dict.items():\n",
    "    df_output[f'{model_name} (Traduzione)'] = translations\n",
    "\n",
    "df_output.to_csv(file_translations_csv, index=False, sep=';')\n",
    "print(f\"File CSV con traduzioni creato: {file_translations_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de08658d-2043-4f77-9217-572e411be2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello: Helsinki-NLP/opus-mt-en-it, Punteggio BLEU: 0.23570952086490674\n",
      "Modello: Gopal1853/Gopal-finetuned-custom-en-to-it, Punteggio BLEU: 0.21251042633583053\n",
      "Modello: Anhptp/opus-mt-en-it-BDS-G1, Punteggio BLEU: 0.22235800555614482\n",
      "Modello: callmyname/marian-finetuned-kde4-en-to-it, Punteggio BLEU: 0.14978396226125565\n",
      "\n",
      "Il miglior modello è: Helsinki-NLP/opus-mt-en-it con punteggio BLEU: 0.23570952086490674\n",
      "File CSV con punteggi BLEU creato: europarl_bleu.csv\n"
     ]
    }
   ],
   "source": [
    "# Parte 2: Calcolo dei punteggi BLEU\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def calculate_bleu(df, translations_dict):\n",
    "    scores = {}\n",
    "\n",
    "    # Converti la colonna \"Italiano\" in stringhe e sostituisci eventuali NaN\n",
    "    original_texts = df['Italiano'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    for model_name, translations in translations_dict.items():\n",
    "        bleu_score = corpus_bleu(\n",
    "            [[ref.split()] for ref in original_texts if isinstance(ref, str)],\n",
    "            [hyp.split() for hyp in translations if isinstance(hyp, str)]\n",
    "        )\n",
    "        scores[model_name] = bleu_score\n",
    "\n",
    "    return scores\n",
    "\n",
    "# Calcola i punteggi BLEU\n",
    "bleu_scores = calculate_bleu(df, translations_dict)\n",
    "\n",
    "# Stampa i punteggi BLEU per tutti i modelli\n",
    "for model_name, score in bleu_scores.items():\n",
    "    print(f\"Modello: {model_name}, Punteggio BLEU: {score}\")\n",
    "\n",
    "# Trova il modello migliore\n",
    "best_model = max(bleu_scores, key=bleu_scores.get)\n",
    "best_model_score = bleu_scores[best_model]\n",
    "\n",
    "print(f\"\\nIl miglior modello è: {best_model} con punteggio BLEU: {best_model_score}\")\n",
    "\n",
    "# Salva i punteggi BLEU nel file CSV\n",
    "for model_name, score in bleu_scores.items():\n",
    "    df_output[f'{model_name} (BLEU: {score:.4f})'] = translations_dict[model_name]\n",
    "\n",
    "file_output_csv = 'europarl_bleu.csv'\n",
    "df_output.to_csv(file_output_csv, index=False, sep=';')\n",
    "print(f\"File CSV con punteggi BLEU creato: {file_output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218884cf-4bfb-48c5-8819-ad46226ed083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delimiter trovato: ','\n",
      "Il delimitatore trovato è: ','\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def detect_delimiter(filepath):\n",
    "    # Legge il file CSV provando con diversi delimitatori comuni\n",
    "    sample_size = 1000  # Numero di righe da leggere per determinare il delimitatore\n",
    "    sample_lines = pd.read_csv(filepath, nrows=sample_size, sep=None, engine='python')\n",
    "\n",
    "    # Ottiene i possibili delimitatori\n",
    "    delimiters = [',', ';', '\\t', '|']\n",
    "\n",
    "    for delim in delimiters:\n",
    "        try:\n",
    "            # Prova a leggere con il delimitatore attuale\n",
    "            sample_lines = pd.read_csv(filepath, delimiter=delim, nrows=sample_size)\n",
    "            print(f\"Delimiter trovato: '{delim}'\")\n",
    "            return delim\n",
    "        except pd.errors.ParserError:\n",
    "            continue\n",
    "\n",
    "    print(\"Delimitatore non riconosciuto.\")\n",
    "    return None\n",
    "\n",
    "# Esempio di utilizzo\n",
    "file_path = 'merged_translcsv'\n",
    "detected_delimiter = detect_delimiter(file_path)\n",
    "if detected_delimiter:\n",
    "    print(f\"Il delimitatore trovato è: '{detected_delimiter}'\")\n",
    "else:\n",
    "    print(\"Non è stato possibile identificare il delimitatore.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99de5d-7a4a-4cf9-8ea4-858f6b283265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-calderini",
   "language": "python",
   "name": "venv-calderini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
